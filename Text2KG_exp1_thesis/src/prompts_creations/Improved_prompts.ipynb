{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa029d-df65-4d03-acb4-581078bbe3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10656f1-b519-4fe8-8b23-daf11b619f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Improved instruction block for high-quality and flexible SPO triple extraction\n",
    "INSTRUCTION_BLOCK = \"\"\"### INSTRUCTION:\n",
    "Your task is to analyze the input text and extract high-quality subject-predicate-object (SPO) triples suitable for constructing a knowledge graph.\n",
    "\n",
    "- Use the provided  Ontology Concepts and Ontology Relations as your primary reference.\n",
    "- You may include new concepts or relations only if they are clearly and unambiguously implied by the sentence.\n",
    "- Ensure all extracted relations are domain-relevant and meaningful.\n",
    "- Avoid inferring or hallucinating facts not stated in the text.\n",
    "- Output only the SPO triples in the format: predicate(subject, object), one per line.\n",
    "- Do NOT include extra commentary, headers, bullet points, or JSON.\n",
    "- Be concise, clean, and precise in your extraction.\"\"\"\n",
    "\n",
    "def enhance_prompt(original_prompt):\n",
    "    \"\"\"\n",
    "    Extracts and restructures a raw prompt into a well-formatted instruction-driven prompt.\n",
    "    It assumes specific markers like 'Ontology Concepts:', 'Example Sentence:', etc., are present.\n",
    "    \"\"\"\n",
    "    parts = {\n",
    "        \"context\": \"\",\n",
    "        \"example_sentence\": \"\",\n",
    "        \"example_output\": \"\",\n",
    "        \"test_sentence\": \"\",\n",
    "        \"test_output\": \"\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Extract index positions of each section\n",
    "        context_start = original_prompt.index(\"Ontology Concepts:\")\n",
    "        example_start = original_prompt.index(\"Example Sentence:\")\n",
    "        example_output_start = original_prompt.index(\"Example Output:\")\n",
    "        test_start = original_prompt.index(\"Test Sentence:\")\n",
    "        test_output_start = original_prompt.index(\"Test Output:\")\n",
    "\n",
    "        # Slice out sections based on markers\n",
    "        parts[\"context\"] = original_prompt[context_start:example_start].strip()\n",
    "        parts[\"example_sentence\"] = original_prompt[example_start:example_output_start].strip()\n",
    "        parts[\"example_output\"] = original_prompt[example_output_start:test_start].strip()\n",
    "        parts[\"test_sentence\"] = original_prompt[test_start:test_output_start].strip()\n",
    "        parts[\"test_output\"] = original_prompt[test_output_start:].strip()\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(\"Skipping malformed prompt:\", e)\n",
    "        return original_prompt  # fallback to original if parsing fails\n",
    "\n",
    "    # Rebuild with improved structure and instruction block\n",
    "    enhanced_prompt = (\n",
    "        f\"{INSTRUCTION_BLOCK}\\n\\n\"\n",
    "        f\"### CONTEXT:\\n{parts['context']}\\n\\n\"\n",
    "        f\"### {parts['example_sentence']}\\n\\n\"\n",
    "        f\"### {parts['example_output']}\\n\\n\"\n",
    "        f\"### {parts['test_sentence']}\\n\\n\"\n",
    "        f\"### {parts['test_output']}\"\n",
    "    )\n",
    "    return enhanced_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57786da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_paths = [\n",
    "    (\"ont_1_university_prompts.jsonl\",        \"ont_1_university_prompts_improved.jsonl\"),\n",
    "    (\"ont_10_comicscharacter_prompts.jsonl\",  \"ont_10_comicscharacter_prompts_improved.jsonl\"),\n",
    "    (\"ont_11_meanoftransportation_prompts.jsonl\", \"ont_11_meanoftransportation_prompts_improved.jsonl\"),\n",
    "    (\"ont_12_monument_prompts.jsonl\",         \"ont_12_monument_prompts_improved.jsonl\"),\n",
    "    (\"ont_13_food_prompts.jsonl\",             \"ont_13_food_prompts_improved.jsonl\"),\n",
    "    (\"ont_14_writtenwork_prompts.jsonl\",      \"ont_14_writtenwork_prompts_improved.jsonl\"),\n",
    "    (\"ont_15_sportsteam_prompts.jsonl\",       \"ont_15_sportsteam_prompts_improved.jsonl\"),\n",
    "    (\"ont_16_city_prompts.jsonl\",             \"ont_16_city_prompts_improved.jsonl\"),\n",
    "    (\"ont_17_artist_prompts.jsonl\",           \"ont_17_artist_prompts_improved.jsonl\"),\n",
    "    (\"ont_18_scientist_prompts.jsonl\",        \"ont_18_scientist_prompts_improved.jsonl\"),\n",
    "    (\"ont_19_film_prompts.jsonl\",             \"ont_19_film_prompts_improved.jsonl\"),\n",
    "    (\"ont_2_musicalwork_prompts.jsonl\",       \"ont_2_musicalwork_prompts_improved.jsonl\"),\n",
    "    (\"ont_3_airport_prompts.jsonl\",           \"ont_3_airport_prompts_improved.jsonl\"),\n",
    "    (\"ont_4_building_prompts.jsonl\",          \"ont_4_building_prompts_improved.jsonl\"),\n",
    "    (\"ont_5_athlete_prompts.jsonl\",           \"ont_5_athlete_prompts_improved.jsonl\"),\n",
    "    (\"ont_6_politician_prompts.jsonl\",        \"ont_6_politician_prompts_improved.jsonl\"),\n",
    "    (\"ont_7_company_prompts.jsonl\",           \"ont_7_company_prompts_improved.jsonl\"),\n",
    "    (\"ont_8_celestialbody_prompts.jsonl\",     \"ont_8_celestialbody_prompts_improved.jsonl\"),\n",
    "    (\"ont_9_astronaut_prompts.jsonl\",         \"ont_9_astronaut_prompts_improved.jsonl\"),\n",
    "]\n",
    "\n",
    "base_input_path = \"/upb/users/b/balram/profiles/unix/cs/Text2KG_exp1_thesis/data/input/dbpedia/baseline_input_prompts/\"\n",
    "base_output_path = \"/upb/users/b/balram/profiles/unix/cs/Text2KG_exp1_thesis/data/input/dbpedia/improved_input_prompts/\"\n",
    "\n",
    "for in_file, out_file in input_output_paths:\n",
    "    input_path = base_input_path + in_file\n",
    "    #output_path = base_output_path + out_file\n",
    "    print(((input_path)))\n",
    "    #print(f\"Output: {output_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ea28b-ffdf-4747-8cd7-6cda6a27fe30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_pipeline",
   "language": "python",
   "name": "kg_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
